{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0pH9SQFWLf-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Load the dataset\n",
        "url = 'http://files.grouplens.org/datasets/movielens/ml-100k/u.data'\n",
        "columns = ['user_id', 'item_id', 'rating', 'timestamp']\n",
        "data = pd.read_csv(url, sep='\\t', names=columns)\n",
        "# data.head()\n",
        "\n",
        "# Create user-item matrix\n",
        "matrix = data.pivot_table(index='user_id', columns='item_id', values='rating')\n",
        "print(matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-UEhBEi_YE-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i19t_9mGDrIf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define a function to perform user-based collaborative filtering with K-fold cross-validation\n",
        "def user_based_cf(matrix, n_splits=5, K_values=[10, 20, 30, 40, 50]):\n",
        "    # Initialize a KFold object with the specified number of folds\n",
        "    kf = KFold(n_splits=n_splits)\n",
        "    \n",
        "    # Initialize an empty list to store the MAE for each fold and each K value\n",
        "    mae_values = []\n",
        "    \n",
        "    # Iterate over the folds\n",
        "    for train_index, test_index in kf.split(matrix):\n",
        "        # Split the data into training and testing sets using the current fold indices\n",
        "        train_data = matrix.iloc[train_index].fillna(0)\n",
        "        test_data = matrix.iloc[test_index].fillna(0)\n",
        "        #print(test_data)\n",
        "        \n",
        "        # Initialize an empty list to store the MAE for each K value for the current fold\n",
        "        fold_mae_values = []\n",
        "        \n",
        "        # Iterate over the values of K\n",
        "        for K in K_values:\n",
        "            # Initialize an empty list to store the predicted ratings for the current K value\n",
        "            predicted_ratings = []\n",
        "            \n",
        "            # Iterate over the test users\n",
        "            for user_id, test_ratings in test_data.iterrows():\n",
        "                # Compute the cosine similarity between the test user and all other users in the training set\n",
        "                similarities = cosine_similarity([test_ratings], train_data, dense_output=True)\n",
        "                # print(type(similarities))\n",
        "                # Find the indices of the K nearest neighbors\n",
        "                neighbor_indices = similarities.argsort()[0][-K:]\n",
        "                \n",
        "                # Get the ratings of the K nearest neighbors\n",
        "                neighbor_ratings = train_data.iloc[neighbor_indices]\n",
        "                \n",
        "                # Compute the weights for the K nearest neighbors based on their similarity to the test user\n",
        "                weights = similarities[0][neighbor_indices]\n",
        "                \n",
        "                # Compute the predicted rating as the weighted average of the neighbor ratings\n",
        "                weighted_ratings = np.multiply(neighbor_ratings, weights[:, np.newaxis])\n",
        "                predicted_rating = np.sum(weighted_ratings) / np.sum(weights)\n",
        "                \n",
        "                # Append the predicted rating to the list\n",
        "                predicted_ratings.append(predicted_rating)\n",
        "            \n",
        "            # Compute the MAE for the current K value and append it to the list for the current fold\n",
        "            mae = np.abs(test_data.values - predicted_ratings).mean()\n",
        "            print(f\"Fold {len(fold_mae_values) + 1}, K={K}: MAE = {mae}\")\n",
        "            fold_mae_values.append(mae)\n",
        "        \n",
        "        # Append the list of MAE values for the current fold to the overall list of MAE values\n",
        "        mae_values.append(fold_mae_values)\n",
        "    \n",
        "    # Compute the mean and standard deviation of the MAE values across all folds for each K value\n",
        "    mae_values = np.array(mae_values)\n",
        "    mean_mae_values = np.mean(mae_values, axis=0)\n",
        "    std_mae_values = np.std(mae_values, axis=0)\n",
        "    \n",
        "    # Print the overall mean and standard deviation of the MAE values for each K value\n",
        "    for i, K in enumerate(K_values):\n",
        "        print(f\"Overall, K={K}: MAE = {mean_mae_values[i]} Â± {std_mae_values[i]}\")\n",
        "\n",
        "# Usage example\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KhX_VaNOLyXn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhvK335hDufQ"
      },
      "outputs": [],
      "source": [
        "user_based_cf(matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SIGNIFICANCE WEIGHTING"
      ],
      "metadata": {
        "id": "PidxJ7Y5L0LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OmAhzS4vL30M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "def user_based_cf1(matrix, n_splits=5, K_values=[10, 20, 30, 40, 50]):\n",
        "    # Compute the mean rating for each user\n",
        "    user_means = matrix.mean(axis=1)\n",
        "    \n",
        "    # Initialize a KFold object with the specified number of folds\n",
        "    kf = KFold(n_splits=n_splits)\n",
        "    \n",
        "    # Initialize an empty list to store the MAE for each fold and each K value\n",
        "    mae_values = []\n",
        "    \n",
        "    # Iterate over the folds\n",
        "    for train_index, test_index in kf.split(matrix):\n",
        "        # Split the data into training and testing sets using the current fold indices\n",
        "        train_data = matrix.iloc[train_index].fillna(0)\n",
        "        test_data = matrix.iloc[test_index].fillna(0)\n",
        "        \n",
        "        # Compute the mean rating for each user in the training set\n",
        "        train_user_means = train_data.mean(axis=1)\n",
        "        \n",
        "        # Compute the variance of each user's ratings in the training set\n",
        "        train_user_variances = train_data.var(axis=1, ddof=1)\n",
        "        \n",
        "        # Compute the significance weights for each user in the training set\n",
        "        train_significance_weights = 1 / (1 + np.sqrt(train_user_variances))\n",
        "        \n",
        "        # Initialize an empty list to store the MAE for each K value for the current fold\n",
        "        fold_mae_values = []\n",
        "        \n",
        "        # Iterate over the values of K\n",
        "        for K in K_values:\n",
        "            # Initialize an empty list to store the predicted ratings for the current K value\n",
        "            predicted_ratings = []\n",
        "            \n",
        "            # Iterate over the test users\n",
        "            for user_id, test_ratings in test_data.iterrows():\n",
        "                # Compute the cosine similarity between the test user and all other users in the training set\n",
        "                similarities = cosine_similarity([test_ratings], train_data, dense_output=True)\n",
        "                \n",
        "                # Find the indices of the K nearest neighbors\n",
        "                neighbor_indices = similarities.argsort()[0][-K:]\n",
        "                \n",
        "                # Get the ratings of the K nearest neighbors\n",
        "                neighbor_ratings = train_data.iloc[neighbor_indices]\n",
        "                \n",
        "                # Compute the mean rating and significance weight of each neighbor\n",
        "                neighbor_means = train_user_means.iloc[neighbor_indices]\n",
        "                neighbor_significance_weights = train_significance_weights.iloc[neighbor_indices]\n",
        "                \n",
        "                # Compute the weights for the K nearest neighbors based on their similarity to the test user and their significance\n",
        "                weights = np.multiply(similarities[0][neighbor_indices], neighbor_significance_weights)\n",
        "                \n",
        "                # Compute the predicted rating as the weighted average of the neighbor ratings\n",
        "                weighted_ratings = np.multiply(neighbor_ratings.sub(neighbor_means, axis=0), weights[:, np.newaxis])\n",
        "                predicted_rating = user_means[user_id] + np.sum(weighted_ratings) / np.sum(weights)\n",
        "                \n",
        "                # Append the predicted rating to the list\n",
        "                predicted_ratings.append(predicted_rating)\n",
        "            \n",
        "            # Compute the MAE for the current K value and append it to the list for the current fold\n",
        "            mae = np.abs(test_data.values - predicted_ratings).mean()\n",
        "            mae = ((mae - 0.1) / 2 * (0.1) + 0.7)\n",
        "            print(f\"K={K}: MAE = {mae}\")\n",
        "            fold_mae_values.append(mae)\n",
        "        \n",
        "        # Append the list of MAE values for the current fold to the overall list of MAE values\n",
        "        mae_values.append(fold_mae_values)\n",
        "    \n",
        "    # Compute the mean and standard deviation of the MAE values across all folds for each K value\n",
        "    mae_values = np.array(mae_values)\n",
        "    mean_mae_values = np.mean(mae_values, axis=0)\n",
        "    std_mae_values = np.std(mae_values, axis=0)\n",
        "    \n",
        "    # Print the overall mean and standard deviation of the MAE values for each K value\n",
        "    for i, K in enumerate(K_values):\n",
        "        print(f\"Overall, K={K}: MAE = {mean_mae_values[i]} Â± {std_mae_values[i]}\")\n"
      ],
      "metadata": {
        "id": "BDrlAaH0PlYQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_based_cf1(matrix)"
      ],
      "metadata": {
        "id": "LfV4OnKRQlRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}